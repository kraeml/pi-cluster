{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Docker Swarm with Blinkt!\n",
    "\n",
    "Was ist Docker?\n",
    "\n",
    "![Container](https://www.docker.com/sites/default/files/Container%402x.png)\n",
    "\n",
    "Containers are an abstraction at the app layer that packages code and dependencies together. Multiple containers can run on the same machine and share the OS kernel with other containers, each running as isolated processes in user space. Containers take up less space than VMs (container images are typically tens of MBs in size), and start almost instantly. \n",
    "\n",
    "![VMs](https://www.docker.com/sites/default/files/VM%402x.png)\n",
    "\n",
    "Virtual machines (VMs) are an abstraction of physical hardware turning one server into many servers. The hypervisor allows multiple VMs to run on a single machine. Each VM includes a full copy of an operating system, one or more apps, necessary binaries and libraries - taking up tens of GBs. VMs can also be slow to boot.\n",
    "\n",
    "## Init Docker Swarm on Cluster\n",
    "\n",
    "Zunächst die IP-Adresse feststellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n",
      "    link/ether b8:27:eb:27:c2:35 brd ff:ff:ff:ff:ff:ff\n",
      "    inet 172.24.2.1/24 brd 172.24.2.255 scope global eth0\n",
      "       valid_lft forever preferred_lft forever\n",
      "    inet 192.168.56.192/24 brd 192.168.56.255 scope global eth0\n",
      "       valid_lft forever preferred_lft forever\n",
      "    inet6 fd00::ba27:ebff:fe27:c235/64 scope global mngtmpaddr dynamic \n",
      "       valid_lft 7148sec preferred_lft 3548sec\n",
      "    inet6 fe80::ba27:ebff:fe27:c235/64 scope link \n",
      "       valid_lft forever preferred_lft forever\n"
     ]
    }
   ],
   "source": [
    "ip addr show eth0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.24.2.1\n"
     ]
    }
   ],
   "source": [
    "ip addr show eth0 | grep 'inet\\s' | awk '{ print $2}' | cut -d '/' -f 1 | grep 172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.24.2.1\n"
     ]
    }
   ],
   "source": [
    "IP_LEADER=$(ip a s eth0 | grep 'inet\\s' | awk '{ print $2}' | cut -d '/' -f 1 | grep  172)\n",
    "echo $IP_LEADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.24.1.1\n"
     ]
    }
   ],
   "source": [
    "IP_LEADER_WLAN=$(ip a s wlan0 | grep 'inet\\s' | awk '{ print $2}' | cut -d '/' -f 1)\n",
    "echo $IP_LEADER_WLAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker node ls\n",
      "Error response from daemon: This node is not a swarm manager. Use \"docker swarm init\" or \"docker swarm join\" to connect this node to swarm and try again.\n",
      "+ docker swarm init --advertise-addr 172.24.2.1\n",
      "Swarm initialized: current node (ugcpx4yfubk6t7db7q0mpxom2) is now a manager.\n",
      "\n",
      "To add a worker to this swarm, run the following command:\n",
      "\n",
      "    docker swarm join --token SWMTKN-1-4km9bpw27yny1njsxc60luhl3l2wtqtrz0l2meafc64y1n8zwh-9mfuh5lur7l7xoxlg313a2n7f 172.24.2.1:2377\n",
      "\n",
      "To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n",
      "\n",
      "+ docker node ls\n",
      "ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS\n",
      "ugcpx4yfubk6t7db7q0mpxom2 *   cluster-00          Ready               Active              Leader\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "docker node ls || docker swarm init --advertise-addr ${IP_LEADER} && docker node ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ docker swarm join-token -q worker\n",
      "+ JOIN_TOKEN=SWMTKN-1-4km9bpw27yny1njsxc60luhl3l2wtqtrz0l2meafc64y1n8zwh-9mfuh5lur7l7xoxlg313a2n7f\n",
      "+ echo SWMTKN-1-4km9bpw27yny1njsxc60luhl3l2wtqtrz0l2meafc64y1n8zwh-9mfuh5lur7l7xoxlg313a2n7f\n",
      "SWMTKN-1-4km9bpw27yny1njsxc60luhl3l2wtqtrz0l2meafc64y1n8zwh-9mfuh5lur7l7xoxlg313a2n7f\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "JOIN_TOKEN=$(docker swarm join-token -q worker)\n",
    "echo $JOIN_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ docker swarm join-token -q manager\n",
      "+ JOIN_TOKEN_MANAGER=SWMTKN-1-4km9bpw27yny1njsxc60luhl3l2wtqtrz0l2meafc64y1n8zwh-85qfq5zcnmrdnbsqy5htj5k0k\n",
      "+ echo SWMTKN-1-4km9bpw27yny1njsxc60luhl3l2wtqtrz0l2meafc64y1n8zwh-85qfq5zcnmrdnbsqy5htj5k0k\n",
      "SWMTKN-1-4km9bpw27yny1njsxc60luhl3l2wtqtrz0l2meafc64y1n8zwh-85qfq5zcnmrdnbsqy5htj5k0k\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "JOIN_TOKEN_MANAGER=$(docker swarm join-token -q manager)\n",
    "echo $JOIN_TOKEN_MANAGER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSH einrichten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pi/.ssh/id_rsa\n"
     ]
    }
   ],
   "source": [
    "# Setup ssh-key for user if not exists\n",
    "ls ~/.ssh/id_rsa || ansible -i localhost, -m shell -a 'ssh-keygen -b 2048 -t rsa -f ~/.ssh/id_rsa -q -N \"\" creates=~/.ssh/id_rsa' --connection=local localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den SSH Zugang vorbereiten. Zunächst aus `knwon_hosts` löschen. Dann wieder bekannt geben und den ssh-key übertragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PING cluster-01.local (172.24.2.2) 56(84) bytes of data.\n",
      "64 bytes from 172.24.2.2: icmp_seq=1 ttl=64 time=0.852 ms\n",
      "\n",
      "--- cluster-01.local ping statistics ---\n",
      "1 packets transmitted, 1 received, 0% packet loss, time 0ms\n",
      "rtt min/avg/max/mdev = 0.852/0.852/0.852/0.000 ms\n"
     ]
    }
   ],
   "source": [
    "ping -c 1 cluster-01.local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.24.2.2\n"
     ]
    }
   ],
   "source": [
    "ping -c 1 cluster-01.local | grep PING | cut -d '(' -f 2 | cut -d')' -f 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pi/.ssh/known_hosts updated.\n",
      "Original contents retained as /home/pi/.ssh/known_hosts.old\n",
      "# Host cluster-01.local found: line 35 type RSA\n",
      "# Host cluster-01.local found: line 36 type ECDSA\n",
      "# Host cluster-01.local found: line 37 type ED25519\n",
      "/home/pi/.ssh/known_hosts updated.\n",
      "Original contents retained as /home/pi/.ssh/known_hosts.old\n",
      "# Host 172.24.2.2 found: line 35 type ED25519\n",
      "# Host 172.24.2.2 found: line 36 type RSA\n",
      "# Host 172.24.2.2 found: line 37 type ECDSA\n",
      "/home/pi/.ssh/known_hosts updated.\n",
      "Original contents retained as /home/pi/.ssh/known_hosts.old\n",
      "# cluster-01.local SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-01.local SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-01.local SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-01 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-01 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-01 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# 172.24.2.2 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# 172.24.2.2 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# 172.24.2.2 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n",
      "\n",
      "/usr/bin/ssh-copy-id: WARNING: All keys were skipped because they already exist on the remote system.\n",
      "\n",
      "/home/pi/.ssh/known_hosts updated.\n",
      "Original contents retained as /home/pi/.ssh/known_hosts.old\n",
      "# Host cluster-02.local found: line 35 type ECDSA\n",
      "# Host cluster-02.local found: line 36 type RSA\n",
      "# Host cluster-02.local found: line 37 type ED25519\n",
      "/home/pi/.ssh/known_hosts updated.\n",
      "Original contents retained as /home/pi/.ssh/known_hosts.old\n",
      "# Host 172.24.2.3 found: line 35 type ECDSA\n",
      "# Host 172.24.2.3 found: line 36 type RSA\n",
      "# Host 172.24.2.3 found: line 37 type ED25519\n",
      "/home/pi/.ssh/known_hosts updated.\n",
      "Original contents retained as /home/pi/.ssh/known_hosts.old\n",
      "# cluster-02.local SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-02.local SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-02.local SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-02 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-02 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-02 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# 172.24.2.3 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# 172.24.2.3 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# 172.24.2.3 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n",
      "\n",
      "/usr/bin/ssh-copy-id: WARNING: All keys were skipped because they already exist on the remote system.\n",
      "\n",
      "/home/pi/.ssh/known_hosts updated.\n",
      "Original contents retained as /home/pi/.ssh/known_hosts.old\n",
      "# Host cluster-03.local found: line 35 type ED25519\n",
      "# Host cluster-03.local found: line 36 type RSA\n",
      "# Host cluster-03.local found: line 37 type ECDSA\n",
      "/home/pi/.ssh/known_hosts updated.\n",
      "Original contents retained as /home/pi/.ssh/known_hosts.old\n",
      "# Host 172.24.2.4 found: line 35 type RSA\n",
      "# Host 172.24.2.4 found: line 36 type ECDSA\n",
      "# Host 172.24.2.4 found: line 37 type ED25519\n",
      "/home/pi/.ssh/known_hosts updated.\n",
      "Original contents retained as /home/pi/.ssh/known_hosts.old\n",
      "# cluster-03.local SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-03.local SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-03.local SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-03 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-03 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-03 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# 172.24.2.4 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# 172.24.2.4 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# 172.24.2.4 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n",
      "\n",
      "/usr/bin/ssh-copy-id: WARNING: All keys were skipped because they already exist on the remote system.\n",
      "\n",
      "/home/pi/.ssh/known_hosts updated.\n",
      "Original contents retained as /home/pi/.ssh/known_hosts.old\n",
      "# Host cluster-04.local found: line 35 type ECDSA\n",
      "# Host cluster-04.local found: line 36 type RSA\n",
      "# Host cluster-04.local found: line 37 type ED25519\n",
      "/home/pi/.ssh/known_hosts updated.\n",
      "Original contents retained as /home/pi/.ssh/known_hosts.old\n",
      "# Host 172.24.2.5 found: line 35 type ECDSA\n",
      "# Host 172.24.2.5 found: line 36 type ED25519\n",
      "# Host 172.24.2.5 found: line 37 type RSA\n",
      "/home/pi/.ssh/known_hosts updated.\n",
      "Original contents retained as /home/pi/.ssh/known_hosts.old\n",
      "# cluster-04.local SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-04.local SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-04.local SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-04 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-04 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# cluster-04 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# 172.24.2.5 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# 172.24.2.5 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "# 172.24.2.5 SSH-2.0-OpenSSH_6.7p1 Raspbian-5+deb8u3\n",
      "/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n",
      "\n",
      "/usr/bin/ssh-copy-id: WARNING: All keys were skipped because they already exist on the remote system.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in 01 02 03 04; do\n",
    "    # Hostname only\n",
    "    CL_HOSTNAME=cluster-${i}\n",
    "    # Get Ip via local Domain (avahi)\n",
    "    CL_IP=$(ping -c 1 ${CL_HOSTNAME}.local | grep PING | cut -d '(' -f 2 | cut -d')' -f 1)\n",
    "    # Cluster Hostname only\n",
    "    ssh-keygen -R ${CL_HOSTNAME}\n",
    "    # Cluster with Domain local\n",
    "    ssh-keygen -R ${CL_HOSTNAME}.local\n",
    "    # IP Cluster \n",
    "    ssh-keygen -R ${CL_IP}\n",
    "    # Add Cluster into known_hosts\n",
    "    ssh-keyscan -H ${CL_HOSTNAME}.local >> ~/.ssh/known_hosts\n",
    "    ssh-keyscan -H ${CL_HOSTNAME} >> ~/.ssh/known_hosts\n",
    "    ssh-keyscan -H ${CL_IP} >> ~/.ssh/known_hosts\n",
    "    # SSH key copy into Cluster\n",
    "    sshpass -p raspberry ssh-copy-id pi@${CL_HOSTNAME}.local\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dem Swarm beitreten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker node ls\n",
      "ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS\n",
      "ugcpx4yfubk6t7db7q0mpxom2 *   cluster-00          Ready               Active              Leader\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "docker node ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nur der Client 01 und 03 als Worker dem Swarm beitreten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ for i in 01 03\n",
      "+ CL_HOSTNAME=cluster-01.local\n",
      "+ echo cluster-01.local\n",
      "cluster-01.local\n",
      "+ ssh cluster-01.local 'docker swarm join --token SWMTKN-1-4km9bpw27yny1njsxc60luhl3l2wtqtrz0l2meafc64y1n8zwh-9mfuh5lur7l7xoxlg313a2n7f 172.24.2.1:2377'\n",
      "This node joined a swarm as a worker.\n",
      "+ for i in 01 03\n",
      "+ CL_HOSTNAME=cluster-03.local\n",
      "+ echo cluster-03.local\n",
      "cluster-03.local\n",
      "+ ssh cluster-03.local 'docker swarm join --token SWMTKN-1-4km9bpw27yny1njsxc60luhl3l2wtqtrz0l2meafc64y1n8zwh-9mfuh5lur7l7xoxlg313a2n7f 172.24.2.1:2377'\n",
      "Error response from daemon: This node is already part of a swarm. Use \"docker swarm leave\" to leave this swarm and join another one.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#set -x\n",
    "for i in 01 03; do\n",
    "    # Hostname only\n",
    "    CL_HOSTNAME=cluster-${i}.local\n",
    "    echo $CL_HOSTNAME\n",
    "    ssh $CL_HOSTNAME \"docker swarm join --token $JOIN_TOKEN $IP_LEADER:2377\"\n",
    "done\n",
    "#set +x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker node ls\n",
      "ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS\n",
      "ugcpx4yfubk6t7db7q0mpxom2 *   cluster-00          Ready               Active              Leader\n",
      "ka0dfxhvbag77ntfgd9khjfau     cluster-01          Ready               Active              \n",
      "jb1aby9ts5431iwtil5fclw9c     cluster-02          Ready               Active              Reachable\n",
      "iv7y5mae02lt10tabbsy4cf71     cluster-03          Ready               Active              \n",
      "jacutj39mit02u59ogc92aaks     cluster-04          Ready               Active              Reachable\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "docker node ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ set -x\n",
      "+ for i in 02 04\n",
      "+ CL_HOSTNAME=cluster-02.local\n",
      "+ echo cluster-02.local\n",
      "cluster-02.local\n",
      "+ ssh cluster-02.local 'docker swarm join --token SWMTKN-1-4km9bpw27yny1njsxc60luhl3l2wtqtrz0l2meafc64y1n8zwh-85qfq5zcnmrdnbsqy5htj5k0k 172.24.2.1:2377'\n",
      "This node joined a swarm as a manager.\n",
      "+ for i in 02 04\n",
      "+ CL_HOSTNAME=cluster-04.local\n",
      "+ echo cluster-04.local\n",
      "cluster-04.local\n",
      "+ ssh cluster-04.local 'docker swarm join --token SWMTKN-1-4km9bpw27yny1njsxc60luhl3l2wtqtrz0l2meafc64y1n8zwh-85qfq5zcnmrdnbsqy5htj5k0k 172.24.2.1:2377'\n",
      "This node joined a swarm as a manager.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "for i in 02 04; do\n",
    "    # Hostname only\n",
    "    CL_HOSTNAME=cluster-${i}.local\n",
    "    echo $CL_HOSTNAME\n",
    "    ssh $CL_HOSTNAME \"docker swarm join --token $JOIN_TOKEN_MANAGER $IP_LEADER:2377\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker node ls\n",
      "ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS\n",
      "ugcpx4yfubk6t7db7q0mpxom2 *   cluster-00          Ready               Active              Leader\n",
      "jb1aby9ts5431iwtil5fclw9c     cluster-02          Ready               Active              Reachable\n",
      "iv7y5mae02lt10tabbsy4cf71     cluster-03          Ready               Active              \n",
      "jacutj39mit02u59ogc92aaks     cluster-04          Ready               Active              Reachable\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "docker node ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizer anschauen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einen graphischen Output als Service starten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service create \\\n",
    "  --name=visualizer \\\n",
    "  --publish=8000:8080/tcp \\\n",
    "  --constraint=node.role==manager \\\n",
    "  --mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \\\n",
    "  --no-resolve-image \\\n",
    "  --detach=false \\\n",
    "  alexellis2/visualizer-arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"http://${IP_LEADER_WLAN}:8000\"\n",
    "echo \"http://${IP_LEADER}:8000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf allen nodes den Monitor Dienst installieren. Dieser überwacht, wie viele whoami Container laufen.\n",
    "\n",
    "Grün: Ein whoami-Container wird gestartet.\n",
    "\n",
    "Rot: Ein whoami-Container stoppt.\n",
    "\n",
    "Gelb: Für die Version 1.1.0\n",
    "\n",
    "Blau: Für die Version 1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service create --name monitor --mode global \\\n",
    "  --restart-condition any --mount type=bind,src=/sys,dst=/sys \\\n",
    "  --mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \\\n",
    "  --no-resolve-image \\\n",
    "  --detach=false \\\n",
    "  stefanscherer/monitor:1.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es läuft noch kein whoami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service create --name whoami \\\n",
    "  --no-resolve-image \\\n",
    "  --detach=false \\\n",
    "  stefanscherer/whoami:1.1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service update \\\n",
    "  --detach=false \\\n",
    "  --image stefanscherer/whoami:1.2.0 whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service scale --detach=false whoami=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service update \\\n",
    "  --detach=false \\\n",
    "  --image stefanscherer/whoami:1.1.0 whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service scale --detach=false whoami=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service update --update-parallelism 5 \\\n",
    "  --detach=false \\\n",
    "  --image stefanscherer/whoami:1.2.0 whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service scale --detach=false whoami=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service update --update-parallelism 5 \\\n",
    "  --detach=false \\\n",
    "  --image stefanscherer/whoami:1.1.0 whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service scale --detach=false whoami=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service scale --detach=false whoami=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service update --update-parallelism 5 \\\n",
    "  --detach=false \\\n",
    "  --image stefanscherer/whoami:1.2.0 whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service update --update-parallelism 5 \\\n",
    "  --detach=false \\\n",
    "  --image stefanscherer/whoami:1.1.0 whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "END=5\n",
    "for i in $(seq 1 $END); do\n",
    "    docker service update --update-parallelism 5 \\\n",
    "        --detach=false \\\n",
    "        --image stefanscherer/whoami:1.1.0 whoami --detach=false\n",
    "    docker service scale --detach=false whoami=1 \n",
    "    docker service update --update-parallelism 5 \\\n",
    "        --detach=false \\\n",
    "        --image stefanscherer/whoami:1.2.0 whoami --detach=false\n",
    "    sleep 5\n",
    "    docker service scale --detach=false whoami=15\n",
    "    docker service update --update-parallelism 5 \\\n",
    "        --detach=false \\\n",
    "        --image stefanscherer/whoami:1.1.0 whoami --detach=false\n",
    "    sleep 5\n",
    "    docker service update --update-parallelism 5 \\\n",
    "        --detach=false \\\n",
    "        --image stefanscherer/whoami:1.2.0 whoami --detach=false\n",
    "    sleep 5\n",
    "    docker service scale --detach=false whoami=40\n",
    "    sleep 5\n",
    "    docker service update --update-parallelism 5 \\\n",
    "        --detach=false \\\n",
    "        --image stefanscherer/whoami:1.1.0 whoami --detach=false\n",
    "    sleep 5\n",
    "    docker service update --update-parallelism 5 \\\n",
    "        --detach=false \\\n",
    "        --image stefanscherer/whoami:1.2.0 whoami --detach=false\n",
    "    sleep 5\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter nbconvert Jupyter\\ Slides.ipynb --to slides --post serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufräumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service rm whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service rm monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker node ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 01 02 03 04; do\n",
    "    ssh cluster-${i}.local \"docker swarm leave --force\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker node ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker service rm visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker swarm leave --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 01 02 03 04 00; do\n",
    "    ssh cluster-${i}.local \"sudo reboot &\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
